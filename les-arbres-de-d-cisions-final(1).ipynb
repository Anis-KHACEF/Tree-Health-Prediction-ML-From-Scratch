{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91df3346",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:35.535110Z",
     "iopub.status.busy": "2025-04-09T23:30:35.534619Z",
     "iopub.status.idle": "2025-04-09T23:30:36.705574Z",
     "shell.execute_reply": "2025-04-09T23:30:36.704178Z"
    },
    "papermill": {
     "duration": 1.178694,
     "end_time": "2025-04-09T23:30:36.707810",
     "exception": false,
     "start_time": "2025-04-09T23:30:35.529116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/are-sd-2025-classification-diagnostique-d-arbres/benchmark.csv\n",
      "/kaggle/input/are-sd-2025-classification-diagnostique-d-arbres/prev.csv\n",
      "/kaggle/input/are-sd-2025-classification-diagnostique-d-arbres/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session~\n",
    "#a lward ifires djilali d ahwawi ihemmey adihewes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273724fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:36.717327Z",
     "iopub.status.busy": "2025-04-09T23:30:36.716849Z",
     "iopub.status.idle": "2025-04-09T23:30:38.929737Z",
     "shell.execute_reply": "2025-04-09T23:30:38.928223Z"
    },
    "papermill": {
     "duration": 2.219912,
     "end_time": "2025-04-09T23:30:38.931984",
     "exception": false,
     "start_time": "2025-04-09T23:30:36.712072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6168111",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:38.941599Z",
     "iopub.status.busy": "2025-04-09T23:30:38.940883Z",
     "iopub.status.idle": "2025-04-09T23:30:39.036246Z",
     "shell.execute_reply": "2025-04-09T23:30:39.034692Z"
    },
    "papermill": {
     "duration": 0.102307,
     "end_time": "2025-04-09T23:30:39.038220",
     "exception": false,
     "start_time": "2025-04-09T23:30:38.935913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quartier</th>\n",
       "      <th>site</th>\n",
       "      <th>genre_arbre</th>\n",
       "      <th>situation</th>\n",
       "      <th>type_sol</th>\n",
       "      <th>surf_permeable</th>\n",
       "      <th>classe_age</th>\n",
       "      <th>hauteur</th>\n",
       "      <th>classe_hauteur</th>\n",
       "      <th>diametre</th>\n",
       "      <th>...</th>\n",
       "      <th>fissure_houppier</th>\n",
       "      <th>ecorce_incluse_houppier</th>\n",
       "      <th>bois_mort_houppier</th>\n",
       "      <th>plaie_houppier</th>\n",
       "      <th>observation_houppier</th>\n",
       "      <th>esperance_maintien</th>\n",
       "      <th>contrainte</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_ARBRE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>Quartier 2 - Alsace - Pereire</td>\n",
       "      <td>Avenue du Maréchal Foch</td>\n",
       "      <td>Tilia</td>\n",
       "      <td>Alignement</td>\n",
       "      <td>MA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A</td>\n",
       "      <td>800</td>\n",
       "      <td>H2</td>\n",
       "      <td>44.563384</td>\n",
       "      <td>...</td>\n",
       "      <td>HPF</td>\n",
       "      <td>Non</td>\n",
       "      <td>HPBM</td>\n",
       "      <td>HPLNC</td>\n",
       "      <td>Branches cassées</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Non</td>\n",
       "      <td>2.084</td>\n",
       "      <td>48.904</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Quartier 4 - Rotondes - St Léger</td>\n",
       "      <td>Avenue Saint-Fiacre</td>\n",
       "      <td>Carpinus</td>\n",
       "      <td>Alignement</td>\n",
       "      <td>Gr</td>\n",
       "      <td>1.0</td>\n",
       "      <td>JA</td>\n",
       "      <td>800</td>\n",
       "      <td>H2</td>\n",
       "      <td>38.197186</td>\n",
       "      <td>...</td>\n",
       "      <td>HPF</td>\n",
       "      <td>Non</td>\n",
       "      <td>HPBM</td>\n",
       "      <td>HPLS</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Non</td>\n",
       "      <td>2.072</td>\n",
       "      <td>48.895</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Quartier 2 - Alsace - Pereire</td>\n",
       "      <td>Avenue du Maréchal Foch</td>\n",
       "      <td>Tilia</td>\n",
       "      <td>Alignement</td>\n",
       "      <td>MA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A</td>\n",
       "      <td>800</td>\n",
       "      <td>H2</td>\n",
       "      <td>63.661977</td>\n",
       "      <td>...</td>\n",
       "      <td>HPF</td>\n",
       "      <td>Non</td>\n",
       "      <td>HPBM</td>\n",
       "      <td>HPLS</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Non</td>\n",
       "      <td>2.083</td>\n",
       "      <td>48.904</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  quartier                     site  \\\n",
       "ID_ARBRE                                                              \n",
       "559          Quartier 2 - Alsace - Pereire  Avenue du Maréchal Foch   \n",
       "560       Quartier 4 - Rotondes - St Léger      Avenue Saint-Fiacre   \n",
       "561          Quartier 2 - Alsace - Pereire  Avenue du Maréchal Foch   \n",
       "\n",
       "         genre_arbre   situation type_sol  surf_permeable classe_age  hauteur  \\\n",
       "ID_ARBRE                                                                        \n",
       "559            Tilia  Alignement       MA             4.0          A      800   \n",
       "560         Carpinus  Alignement       Gr             1.0         JA      800   \n",
       "561            Tilia  Alignement       MA             4.0          A      800   \n",
       "\n",
       "         classe_hauteur   diametre  ...  fissure_houppier  \\\n",
       "ID_ARBRE                            ...                     \n",
       "559                  H2  44.563384  ...              HPF    \n",
       "560                  H2  38.197186  ...              HPF    \n",
       "561                  H2  63.661977  ...              HPF    \n",
       "\n",
       "         ecorce_incluse_houppier bois_mort_houppier plaie_houppier  \\\n",
       "ID_ARBRE                                                             \n",
       "559                          Non              HPBM           HPLNC   \n",
       "560                          Non              HPBM            HPLS   \n",
       "561                          Non              HPBM            HPLS   \n",
       "\n",
       "         observation_houppier esperance_maintien contrainte   Long     Lat  \\\n",
       "ID_ARBRE                                                                     \n",
       "559         Branches cassées                 2.0        Non  2.084  48.904   \n",
       "560                         0                1.0        Non  2.072  48.895   \n",
       "561                         0                2.0        Non  2.083  48.904   \n",
       "\n",
       "            Usage  \n",
       "ID_ARBRE           \n",
       "559       Private  \n",
       "560       Private  \n",
       "561       Private  \n",
       "\n",
       "[3 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/are-sd-2025-classification-diagnostique-d-arbres/train.csv', index_col='ID_ARBRE')\n",
    "prev_data = pd.read_csv('/kaggle/input/are-sd-2025-classification-diagnostique-d-arbres/prev.csv', index_col='ID_ARBRE')\n",
    "prev_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eba7f5",
   "metadata": {
    "papermill": {
     "duration": 0.003814,
     "end_time": "2025-04-09T23:30:39.046542",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.042728",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e08a801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.056564Z",
     "iopub.status.busy": "2025-04-09T23:30:39.056028Z",
     "iopub.status.idle": "2025-04-09T23:30:39.076152Z",
     "shell.execute_reply": "2025-04-09T23:30:39.074954Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.027758,
     "end_time": "2025-04-09T23:30:39.078379",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.050621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd \n",
    "\n",
    "def label_encoder(feature_vector):\n",
    "    \"\"\"\n",
    "    Encode les catégories/étiquettes des données (en texte) en entier\n",
    "    \"\"\"\n",
    "    unique_labels, encoded_labels = np.unique(feature_vector, return_inverse=True)\n",
    "    return encoded_labels\n",
    "\n",
    "\n",
    "def gini_impurity(labels : np.ndarray):\n",
    "    \"\"\"\n",
    "    Calcul l'impureté de Gini pour un ensemble de prédictions.\n",
    "\n",
    "    L'idée de l'impureté de Gini est la probabilité de se tromper dans une prédiction si on la prenanit au hasard au sein\n",
    "    d'un échantillon donné.\n",
    "\n",
    "    Entrées :\n",
    "        labels : Un tableau de prédiction\n",
    "\n",
    "    Sortie:\n",
    "        La valeur d'impureté de Gini (float)\n",
    "    \"\"\"\n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    probabilities = counts/len(labels)\n",
    "    return 1.-np.sum(probabilities**2)\n",
    "\n",
    "\n",
    "def split_data( train_data : np.ndarray, labels : np.ndarray, feature_index : int, threshold : float):\n",
    "    \"\"\"\n",
    "    Partitionne un ensemble d'entraînement (et de réponse) par rapport à une valeur de seuil.\n",
    "\n",
    "    Entrée:\n",
    "        train_data    : L'ensemble des données d'entraînement\n",
    "        labels        : Les réponses correspondantes aux données d'entraînement\n",
    "        feature_index : L'index du l'étiquette par rapport à laquelle on effectue le partitionnement\n",
    "        threshold     : Le seuil définissant le partitionnement\n",
    "    \"\"\"\n",
    "    left_mask  = train_data[:, feature_index] < threshold\n",
    "    right_mask = ~left_mask\n",
    "    return train_data[left_mask], labels[left_mask], train_data[right_mask], labels[right_mask]\n",
    "\n",
    "\n",
    "def find_best_split(train_data : np.ndarray, labels : np.ndarray):\n",
    "    \"\"\"\n",
    "    Trouve le meilleur partitionnement pour un ensemble de données d'entrée\n",
    "\n",
    "    Entrées:\n",
    "        train_data : Les données d'entrée\n",
    "        labels     : Les prédictions correspondant à chaque entrée de l'entraînement\n",
    "    \n",
    "    Sortie:\n",
    "        La meilleur étiquette (son index en fait) et la valeur de seuil pour son partitionnement\n",
    "    \"\"\"\n",
    "    best_feature, best_threshold, best_gini = None, None, float('inf')\n",
    "    for feature_index in range(train_data.shape[1]):\n",
    "        # Récupère toutes les valeurs mesurées par l'étiquette courante (dans la boucle)\n",
    "        values = np.unique(train_data[:, feature_index])\n",
    "        # Recherche du seuil optimal pour cette étiquette :\n",
    "        for threshold in values:\n",
    "            _, left_labels, _, right_labels = split_data(train_data, labels, feature_index, threshold)\n",
    "            if len(left_labels) == 0 or len(right_labels) == 0: continue\n",
    "            # Calcul de l'indice de gini:\n",
    "            gini = (len(left_labels)*gini_impurity(left_labels) + len(right_labels)*gini_impurity(right_labels)) / len(labels)\n",
    "            # Plus l'indice de gini est petit, mieux c'est\n",
    "            if gini < best_gini:\n",
    "                best_feature, best_threshold, best_gini = feature_index, threshold, gini\n",
    "    return best_feature, best_threshold\n",
    "\n",
    "\n",
    "def build_tree(train_data : np.ndarray, labels : np.ndarray, max_depth : int, min_samples_split : int, depth : int =  0):\n",
    "    \"\"\"\n",
    "    Construit un arbre de décision récursivement\n",
    "\n",
    "    Entrées :\n",
    "        train_data        : Les données d'entrée\n",
    "        labels            : Les prédictions correspondant à chaque entrée de l'entraînement\n",
    "        max_depth         : La profondeur maximale de l'arbre\n",
    "        min_samples_split : Le nombre d'échantillons minimal requis pour partitionner un noeud de l'arbre\n",
    "        depth (optionnel) : La profondeur de l'arbre actuellement traitée (dans la récursion)\n",
    "\n",
    "    Sortie:\n",
    "        L'arbre de décision retourné sous la forme d'un dictionnaire\n",
    "    \"\"\"\n",
    "    if depth == max_depth or len(labels) < min_samples_split or gini_impurity(labels) == 0:\n",
    "        return {'prediction' : np.argmax(np.bincount(labels))}\n",
    "    feature, threshold = find_best_split(train_data, labels)\n",
    "    # Si pas trouvé de feature adéquat, on arrête la construction de la branche et\n",
    "    # on recherche la valeur la plus probable comme réponse (sous forme d'indice) :\n",
    "    if feature is None: return {\"prediction\" : np.argmax(np.bincount(labels))}\n",
    "    left_train_data, left_labels, right_train_data, right_labels = split_data(train_data, labels, feature, threshold)\n",
    "    return {\n",
    "        \"feature\"   : feature,\n",
    "        \"threshold\" : threshold,\n",
    "        \"left\"      : build_tree(left_train_data, left_labels, max_depth, min_samples_split, depth+1),\n",
    "        \"right\"     : build_tree(right_train_data, right_labels, max_depth, min_samples_split, depth+1)\n",
    "    }\n",
    "\n",
    "def predict(tree : dict, data_point : np.ndarray):\n",
    "    \"\"\"\n",
    "    Fait une prédiction pour un simple échantillon utilisant l'arbre de décision\n",
    "\n",
    "    Entrées:\n",
    "        tree       : L'arbre de décision représentée comme un dictionnaire\n",
    "        data_point : L'échantillon d'entrée\n",
    "\n",
    "    Sortie:\n",
    "        La valeur prédite pour l'étiquette\n",
    "    \"\"\"\n",
    "    if 'prediction' in tree:\n",
    "        return tree['prediction']\n",
    "    if data_point[tree['feature']] < tree['threshold']:\n",
    "        return predict(tree['left'], data_point)\n",
    "    else:\n",
    "        return predict(tree['right'], data_point)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1df45e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.090586Z",
     "iopub.status.busy": "2025-04-09T23:30:39.090067Z",
     "iopub.status.idle": "2025-04-09T23:30:39.103579Z",
     "shell.execute_reply": "2025-04-09T23:30:39.102366Z"
    },
    "papermill": {
     "duration": 0.021903,
     "end_time": "2025-04-09T23:30:39.105773",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.083870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_tree(data_prev: pd.DataFrame, data_train: pd.DataFrame, vvar: list, max_depth: int, min_samples_split: int):\n",
    "    \"\"\" Predit la classification de tous les arbre de data_prev, avec comme données d'entrainement \n",
    "    les observations dans data_train en utilisant un seul arbre de décision avec comme paramètres : \n",
    "    mas_depth et min_samples_split en se basant sur les variables : vvars.\n",
    "    \"\"\"\n",
    "    #construction de data_train_for_tree un nd.array qui peut être utilisé dans tree\n",
    "    data_train_for_tree = np.zeros((len(data_train), len(vvar)))\n",
    "    for (i, var) in zip(range(len(vvar)), vvar):\n",
    "        #le cas: var est une variable qualitative\n",
    "        if type(data_train.iloc[0][var]) == str:\n",
    "            data_train_for_tree[:, i] = label_encoder( data_train[var] )\n",
    "        else:\n",
    "            data_train_for_tree[:, i] = data_train[var].to_numpy()\n",
    "\n",
    "    #vecteur (nd.array) contenant les classes des arbres de data_train\n",
    "    data_res = label_encoder(data_train[\"classification_diagnostic\"])\n",
    "    \n",
    "    #creation de l'arbre\n",
    "    tree = build_tree(data_train_for_tree, data_res, max_depth, min_samples_split)\n",
    "\n",
    "    #Les predictions a faire:\n",
    "    obs_a_predire = np.zeros((len(data_prev), len(vvar)), dtype= np.int64)\n",
    "    for j, var in zip(range(len(vvar)), vvar):\n",
    "        if type(data_prev.iloc[0][var]) == str:\n",
    "            #print(label_encoder(data_prev[var]) )\n",
    "            obs_a_predire[:, j] = label_encoder(data_prev[var]) \n",
    "        else:\n",
    "            obs_a_predire[:, j] = data_prev[var].to_numpy()\n",
    "    pred_res = np.array(['  ' for _ in range(len(data_prev))])\n",
    "    for i, obs in zip(range(len(data_prev)), obs_a_predire):\n",
    "        pred_res[i] = (\"C\" + str( predict( tree, obs ) +1))\n",
    "    return pred_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fcfff39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.117197Z",
     "iopub.status.busy": "2025-04-09T23:30:39.116368Z",
     "iopub.status.idle": "2025-04-09T23:30:39.131103Z",
     "shell.execute_reply": "2025-04-09T23:30:39.129208Z"
    },
    "papermill": {
     "duration": 0.022922,
     "end_time": "2025-04-09T23:30:39.133419",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.110497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_forest (data_prev: pd.DataFrame, data_train: pd.DataFrame, vvar: list, max_depth: int, min_samples_split: int, nb_trees : int, nb_vars):\n",
    "    \"\"\" Predit la classification de tous les arbre de data_prev, avec comme données d'entrainement \n",
    "    les observations dans data_train en utilisant une forêt aléatoire de nb_trees arbres de décision avec comme paramètres : \n",
    "    mas_depth et min_samples_split en se basant sur nb_vars variables de vvars choisies aléatoirement pour chaque arbre.\n",
    "    \"\"\"\n",
    "    if len(vvar) < nb_vars:\n",
    "        print(\"ERROR : len(vvar) < nb_vars (boucle infinie) len(varrs) = \", len(vvar))\n",
    "        return 0\n",
    "        \n",
    "    train_long = (4*len(data_train))//5\n",
    "    test_long = len(data_prev)\n",
    "    \n",
    "    votes = np.full((test_long, nb_trees), \"\", dtype='U2')\n",
    "    ind = np.random.permutation(len(vvar))\n",
    "    for i in range(nb_trees):\n",
    "        vars_choisies_ind = np.random.permutation(len(vvar))\n",
    "        vars_choisies = [vvar[i] for i in vars_choisies_ind[0:nb_vars]]\n",
    "        #point a ameliorer : mettre le pourcentage de data_train a prendre en parametres\n",
    "        v_rd = np.random.permutation(data_train.index)        \n",
    "        sous_data_train = data_train[data_train.index.isin(v_rd[:train_long])]\n",
    "        votes[:, i] = predict_tree(data_prev, sous_data_train, vars_choisies, max_depth, min_samples_split)\n",
    "    v_res = np.full(test_long, \"\",dtype='U2')\n",
    "    for i in range(test_long):\n",
    "        val, counts = np.unique(votes[i], return_counts = True)\n",
    "        v_res[i] = val[np.argmax(counts)]\n",
    "    return v_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87573bf",
   "metadata": {
    "papermill": {
     "duration": 0.003921,
     "end_time": "2025-04-09T23:30:39.141677",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.137756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***Entrainement***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc76f01b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.152492Z",
     "iopub.status.busy": "2025-04-09T23:30:39.151773Z",
     "iopub.status.idle": "2025-04-09T23:30:39.161962Z",
     "shell.execute_reply": "2025-04-09T23:30:39.160524Z"
    },
    "papermill": {
     "duration": 0.018201,
     "end_time": "2025-04-09T23:30:39.164512",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.146311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_croisée_tree(data: pd.DataFrame, predi_fonc, v_vars: np.array ,max_depth: int, min_samples_split: int, n_iter: int):\n",
    "    \"\"\"Renvoie le taux de réussite de la prediction du niveau de blessure des arbres par la fonction predi_f \n",
    "    testé sur data_test.\n",
    "    \"\"\"\n",
    "    long = len(data) // 5\n",
    "    res = []\n",
    "    for i in range(n_iter):\n",
    "        v_rd = np.random.permutation(data.index)\n",
    "        data_test = data[data.index.isin(v_rd[:long])]\n",
    "        data_train = data[data.index.isin(v_rd[long:])]\n",
    "        prediction = predi_fonc(data_test, data_train, v_vars, max_depth, min_samples_split)\n",
    "        realite = data_test[\"classification_diagnostic\"].to_numpy()\n",
    "        res.append(np.mean(prediction == realite) * 100)\n",
    "    return np.mean(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26fa8176",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.182774Z",
     "iopub.status.busy": "2025-04-09T23:30:39.182324Z",
     "iopub.status.idle": "2025-04-09T23:30:39.190436Z",
     "shell.execute_reply": "2025-04-09T23:30:39.188430Z"
    },
    "papermill": {
     "duration": 0.018945,
     "end_time": "2025-04-09T23:30:39.193197",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.174252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_croisée_foret(data: pd.DataFrame, predi_fonc, v_vars: np.array ,max_depth: int, min_samples_split: int, nb_trees: int, nb_vars: int, n_iter: int):\n",
    "    \"\"\"Renvoie le taux de réussite de la prediction du niveau de blessure des arbres par la fonction predi_f \n",
    "    testé sur data_test.\n",
    "    \"\"\"\n",
    "    long = len(data) // 5\n",
    "    res = []\n",
    "    for i in range(n_iter):\n",
    "        v_rd = np.random.permutation(data.index)\n",
    "        data_test = data[data.index.isin(v_rd[:long])]\n",
    "        data_train = data[data.index.isin(v_rd[long:])]\n",
    "        prediction = predi_fonc(data_test, data_train, v_vars, max_depth, min_samples_split, nb_trees, nb_vars)\n",
    "        realite = data_test[\"classification_diagnostic\"].to_numpy()\n",
    "        res.append(np.mean(prediction == realite) * 100)\n",
    "    return np.mean(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6dbd93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.203491Z",
     "iopub.status.busy": "2025-04-09T23:30:39.203056Z",
     "iopub.status.idle": "2025-04-09T23:30:39.209707Z",
     "shell.execute_reply": "2025-04-09T23:30:39.207452Z"
    },
    "papermill": {
     "duration": 0.014226,
     "end_time": "2025-04-09T23:30:39.211884",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.197658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vars_tout = [\"circonference (en cm)\", \"surf_permeable\",\"hauteur\", \"ecorce_incluse_houppier\", \"diametre\", \"port_arbre\", \"plaie_houppier\", \"fissure_tronc\", \"quartier\", \"contrainte\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8563aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.223313Z",
     "iopub.status.busy": "2025-04-09T23:30:39.222910Z",
     "iopub.status.idle": "2025-04-09T23:30:39.229766Z",
     "shell.execute_reply": "2025-04-09T23:30:39.228602Z"
    },
    "papermill": {
     "duration": 0.015904,
     "end_time": "2025-04-09T23:30:39.232086",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.216182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tqdm import tqdm \\n\\ndico = {\"accuracy\" : [], \"max_depth\" : [], \"min_samples_split\" : [], \"vars\" : []}\\n\\nfor _ in tqdm(range(500)):\\n    rd = np.random.permutation(len(vars_tout))\\n    vars_ch = [vars_tout[i] for i in rd[:6]]\\n    for max_depth in [20, 25, 30, 35, 40, 45]:\\n        for min_samples_split in [5, 10, 15]:\\n            accuracy = validation_croisée_foret(data, random_forest, vars_ch,max_depth , min_samples_split, 50, 5, 30)\\n            dico[\"accuracy\"].append(accuracy)\\n            dico[\"max_depth\"].append(max_depth)\\n            dico[\"min_samples_split\"].append(min_samples_split)\\n            dico[\"vars\"].append(vars_ch)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from tqdm import tqdm \n",
    "\n",
    "dico = {\"accuracy\" : [], \"max_depth\" : [], \"min_samples_split\" : [], \"vars\" : []}\n",
    "\n",
    "for _ in tqdm(range(500)):\n",
    "    rd = np.random.permutation(len(vars_tout))\n",
    "    vars_ch = [vars_tout[i] for i in rd[:6]]\n",
    "    for max_depth in [20, 25, 30, 35, 40, 45]:\n",
    "        for min_samples_split in [5, 10, 15]:\n",
    "            accuracy = validation_croisée_foret(data, random_forest, vars_ch,max_depth , min_samples_split, 50, 5, 30)\n",
    "            dico[\"accuracy\"].append(accuracy)\n",
    "            dico[\"max_depth\"].append(max_depth)\n",
    "            dico[\"min_samples_split\"].append(min_samples_split)\n",
    "            dico[\"vars\"].append(vars_ch)\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44c7b84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:30:39.246754Z",
     "iopub.status.busy": "2025-04-09T23:30:39.246244Z",
     "iopub.status.idle": "2025-04-09T23:30:42.359995Z",
     "shell.execute_reply": "2025-04-09T23:30:42.358902Z"
    },
    "papermill": {
     "duration": 3.12162,
     "end_time": "2025-04-09T23:30:42.361843",
     "exception": false,
     "start_time": "2025-04-09T23:30:39.240223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>ID_ARBRE</th>\n",
       "      <th>classification_diagnostic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>559</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>560</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>561</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>562</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563</td>\n",
       "      <td>C4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>694</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>695</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>696</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>697</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>698</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_ARBRE classification_diagnostic\n",
       "0        559                        C2\n",
       "1        560                        C2\n",
       "2        561                        C2\n",
       "3        562                        C1\n",
       "4        563                        C4\n",
       "..       ...                       ...\n",
       "132      694                        C2\n",
       "133      695                        C1\n",
       "134      696                        C2\n",
       "135      697                        C1\n",
       "136      698                        C2\n",
       "\n",
       "[137 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vvars = [\"circonference (en cm)\", \"surf_permeable\",\"hauteur\", \"ecorce_incluse_houppier\", \"diametre\", \"contrainte\"]\n",
    "predi_tree = random_forest(prev_data, data, vvars, 15, 11, 50, 5)\n",
    "#predi = random_forest(prev_data, data, vvars, 15, 11)\n",
    "index_tree = np.array([i for i in prev_data.index])\n",
    "v_res_tree = np.vstack((index_tree, predi_tree)).T\n",
    "df_tree = pd.DataFrame(v_res_tree, columns=[['ID_ARBRE', 'classification_diagnostic']])\n",
    "df_tree.to_csv(\"vpredi_tree.csv\", index = False)\n",
    "\n",
    "df_tree"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10993933,
     "sourceId": 91132,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.535265,
   "end_time": "2025-04-09T23:30:43.088586",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-09T23:30:31.553321",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
